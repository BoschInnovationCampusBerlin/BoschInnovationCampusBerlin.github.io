# Large Language Models

## Getting Started with LLM Applications: The Architecture Stack

[**Architecture Stack for LLM Applications**](https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications/?utm_source=tldrfounders): This article discusses the emerging architectures for large language model (LLM) applications. It presents a reference architecture for the LLM app stack, which includes the most common systems, tools, and design patterns used by AI startups and tech companies.

## Current LLMs and How to Use Them

- *wait for vendor info here: AWS, Azure, PALM*
    - *make a list of which LLM is offered by which Cloud platform*

## Deep Dive

### Bootcamp Lectures from A to Z

*~45min per episode, summaries are available*

- [LLM Foundations](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/llm-foundations/)
- [Learn to Spell: Prompt Engineering](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/prompt-engineering/)
- [Launch an LLM App in One Hour](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/launch-an-llm-app-in-one-hour/)
- [LLMOps](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/llmops/)
- [UX for Language User Interfaces](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/ux-for-luis/)
- [Augmented Language Models (using you own data)](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/augmented-language-models/)
- [Building Agents with LLMs](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/chase-agents/)

### Prompt Engineering Guides

- [Prompt Engineering Guide](https://www.promptingguide.ai/techniques)
- [Learn Prompting](https://learnprompting.org/docs/intro)

### Tools for Deploying LLMs

- [FastChat](https://github.com/lm-sys/FastChat) - A distributed multi-model LLM serving system with web UI and OpenAI-compatible RESTful APIs.
- [SkyPilot](https://github.com/skypilot-org/skypilot) - Run LLMs and batch jobs on any cloud. Get maximum cost savings, highest GPU availability, and managed execution -- all with a simple interface.
- [vLLM](https://github.com/vllm-project/vllm) - A high-throughput and memory-efficient inference and serving engine for LLMs
- [Text Generation Inference](https://github.com/huggingface/text-generation-inference) - A Rust, Python and gRPC server for text generation inference. Used in production at [HuggingFace](https://huggingface.co/) to power LLMs api-inference widgets.
- [Haystack](https://haystack.deepset.ai/) - an open-source NLP framework that allows you to use LLMs and transformer-based models from Hugging Face, OpenAI and Cohere to interact with your own data.
- [Sidekick](https://github.com/ai-sidekick/sidekick) - Data integration platform for LLMs.
- [LangChain](https://github.com/hwchase17/langchain) - Building applications with LLMs through composability
- [LlamaIndex](https://gpt-index.readthedocs.io/en/latest/index.html) - Data framework for LLM applications to ingest, structure, and access private or domain-specific data
- [LiteChain](https://github.com/rogeriochaves/litechain) - Lightweight alternative to LangChain for composing LLMs
- [magentic](https://github.com/jackmpcollins/magentic) - Seamlessly integrate LLMs as Python functions
- [wechat-chatgpt](https://github.com/fuergaosi233/wechat-chatgpt) - Use ChatGPT On Wechat via wechaty
- [promptfoo](https://github.com/typpo/promptfoo) - Test your prompts. Evaluate and compare LLM outputs, catch regressions, and improve prompt quality.
- [Agenta](https://github.com/agenta-ai/agenta) - Easily build, version, evaluate and deploy your LLM-powered apps.
- [Serge](https://github.com/serge-chat/serge) - a chat interface crafted with llama.cpp for running Alpaca models. No API keys, entirely self-hosted!
- [Langroid](https://github.com/langroid/langroid) - Harness LLMs with Multi-Agent Programming
- [Embedchain](https://github.com/embedchain/embedchain) - Framework to create ChatGPT like bots over your dataset.
* Tooling list is sourced from [here](https://github.com/Hannibal046/Awesome-LLM#tools-for-deploying-llm) + own knowledge
